{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/learneverythingai/Shivam-Modi-Data-Science-Analytics-Course/blob/main/LLM1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D40IZt-tC0nR"
      },
      "source": [
        "## 1. Prompt Engineering Basics\n",
        "\n",
        "Objectives\n",
        "- Load the libraries\n",
        "- Review the format\n",
        "- Cover basic prompts\n",
        "- Review common use cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mts4zrh6C0nS"
      },
      "source": [
        "Below we are loading the necessary libraries, utilities, and configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE6T-l3pC0nT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca14ffef-8868-4160-e142-e1a91cebd99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.353)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.7)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.4)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.70 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.75)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.4->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.4->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.4->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.4->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "# update or install the necessary libraries\n",
        "!pip install openai==0.28\n",
        "!pip install --upgrade langchain\n",
        "!pip install --upgrade python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f_XdQvyC0nV"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "from langchain.llms import OpenAI\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API configuration\n",
        "openai.api_key = \"\"\n",
        "\n",
        "# for LangChain\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"SERPER_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "9zN2JBbTHp3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3HwIvEVC0nZ"
      },
      "outputs": [],
      "source": [
        "def set_open_params(\n",
        "    model=\"text-davinci-003\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "):\n",
        "    \"\"\" set openai parameters\"\"\"\n",
        "\n",
        "    openai_params = {}\n",
        "\n",
        "    openai_params['model'] = model\n",
        "    openai_params['temperature'] = temperature\n",
        "    openai_params['max_tokens'] = max_tokens\n",
        "    openai_params['top_p'] = top_p\n",
        "    openai_params['frequency_penalty'] = frequency_penalty\n",
        "    openai_params['presence_penalty'] = presence_penalty\n",
        "    return openai_params\n",
        "\n",
        "def get_completion(params, prompt):\n",
        "    \"\"\" GET completion from openai api\"\"\"\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        engine = params['model'],\n",
        "        prompt = prompt,\n",
        "        temperature = params['temperature'],\n",
        "        max_tokens = params['max_tokens'],\n",
        "        top_p = params['top_p'],\n",
        "        frequency_penalty = params['frequency_penalty'],\n",
        "        presence_penalty = params['presence_penalty'],\n",
        "    )\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FMxEolLC0na"
      },
      "source": [
        "Basic prompt example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed7bnx3vC0nb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b41f29c-dcc4-4eda-ffa6-cca32dbb1b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " blue\n",
            "\n",
            "The sky is a light blue color during the day, and becomes darker and more of a navy blue color at night.\n"
          ]
        }
      ],
      "source": [
        "params=set_open_params()\n",
        "\n",
        "prompt='The sky is'\n",
        "\n",
        "response=get_completion(params,prompt)\n",
        "\n",
        "#print(response)\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kFZKyd7C0nc",
        "outputId": "cf027f0f-f5f3-4486-e0f6-a852c32b5963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " uncertainty and ambiguity. It is a multidisciplinary field that combines computing, mathematics, statistics, and machine learning to extract useful insights from large datasets. It is used to discover patterns, trends, and correlations in data that can be used to make informed decisions. Data science involves the application of scientific methods, processes, algorithms, and systems to extract and analyze data from different sources and interpret it in order to gain insights and make better predictions. It can be used to create predictive models, build automated systems, optimize decisions, and create strategies.\n"
          ]
        }
      ],
      "source": [
        "params=set_open_params()\n",
        "\n",
        "prompt='Data science is full of'\n",
        "\n",
        "response=get_completion(params,prompt)\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJXO8DCNC0ng"
      },
      "source": [
        "### 1.1 Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5P-wjrwC0nj",
        "outputId": "c47803ef-78b6-405c-e766-b8f0068b3f8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Antibiotics are medications used to treat bacterial infections by either killing the bacteria or preventing them from reproducing, but they are not effective against viral infections and can lead to antibiotic resistance if used inappropriately.\n"
          ]
        }
      ],
      "source": [
        "params=set_open_params(temperature=0.7)\n",
        "\n",
        "prompt=\"\"\"Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\n",
        "\n",
        "Explain the above in one sentence:\"\"\"\n",
        "\n",
        "response=get_completion(params,prompt)\n",
        "print(response.choices[0].text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXCTbYMmC0nk"
      },
      "source": [
        "Exercise: Instruct the model to explain the paragraph in one sentence like \"I am 5\". Do you see any differences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IUaW4fyC0nl"
      },
      "source": [
        "### 1.2 Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ_DJoQLC0nl",
        "outputId": "4fe2c044-ab52-4e02-93d7-1e0a617ab7f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " Its roots."
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "prompt = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n",
        "\n",
        "Context: eplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
        "\n",
        "Question: What was eplizumab was tracing?\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIffoA9BC0nm"
      },
      "source": [
        "Context obtained from here: https://www.nature.com/articles/d41586-023-00400-x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmNXAEu8C0nm"
      },
      "source": [
        "Exercise: Edit prompt and get the model to respond that it isn't sure about the answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtSHU2tAC0nn"
      },
      "source": [
        "### 1.3 Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAfv3DobC0nn",
        "outputId": "94ece475-f1d4-4338-e103-fe13003c43c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " Neutral"
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "prompt = \"\"\"Classify the text into neutral, negative or positive.\n",
        "\n",
        "Text: The food was okay\n",
        "\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnQ_wO20C0nn"
      },
      "source": [
        "Exercise: Modify the prompt to instruct the model to provide an explanation to the answer selected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Gkt_hPC0no"
      },
      "source": [
        "### 1.4 Role Playing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsaJx7shC0no",
        "outputId": "9d44363a-606c-46d9-81c5-36caec0c5fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " Sure! Black holes are incredibly dense and massive objects in the universe that are formed when a massive star collapses under its own gravity. They are so dense that no matter, not even light, can escape their gravitational pull."
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "prompt = \"\"\"The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
        "\n",
        "Human: Hello, who are you?\n",
        "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
        "Human: Can you tell me about the creation of blackholes?\n",
        "AI:\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjTZwP7RC0np"
      },
      "source": [
        "Exercise: Modify the prompt to instruct the model to keep AI responses concise and short."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKWHlmFVC0nq"
      },
      "source": [
        "### 1.5 Code Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6rzrtQoC0nq",
        "outputId": "dd32e771-8363-49c4-b698-8f2c5e0a2e09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nSELECT StudentId, StudentName \nFROM students\nWHERE DepartmentId IN (SELECT DepartmentId \n                       FROM departments \n                       WHERE DepartmentName = 'Computer Science');"
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "prompt = \"\\\"\\\"\\\"\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a MySQL query for all students in the Computer Science Department\\n\\\"\\\"\\\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Y07JGpC0nr"
      },
      "source": [
        "### 1.6 Reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZM7n7VAC0nr",
        "outputId": "8050591b-2bb2-444e-a9ab-3c98fdc95092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\nOdd numbers: 15, 5, 13, 7, 1\nSum = 41\nResult = Odd"
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "\n",
        "Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP6oI8YiC0ns"
      },
      "source": [
        "Exercise: Improve the prompt to have a better structure and output format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tClryM-C0nt"
      },
      "source": [
        "## 2. Advanced Prompting Techniques\n",
        "\n",
        "Objectives:\n",
        "\n",
        "- Cover more advanced techniques for prompting: few-shot, chain-of-thoughts,..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC_YJcXDC0nt"
      },
      "source": [
        "### 2.2 Few-shot prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLDroGHkC0nt",
        "outputId": "69f423ab-3e33-4ea3-cde0-7d3133150b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " The answer is True."
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
        "A: The answer is True.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
        "A: The answer is True.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
        "A: The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "A:\"\"\"\n",
        "\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-hYD2mdC0nu"
      },
      "source": [
        "### 2.3 Chain-of-Thought (CoT) Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ervDiUwDC0nu"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "A:\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OpdwE1ZC0nv"
      },
      "source": [
        "### 2.4 Zero-shot CoT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8rgJ3x9C0n2"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n",
        "\n",
        "Let's think step by step.\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ka-qGHUC0n2"
      },
      "source": [
        "### 2.6 PAL - Code as Reasoning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr8C2Jn1C0n3"
      },
      "source": [
        "We are developing a simple application that's able to reason about the question being asked through code.\n",
        "\n",
        "Specifically, the application takes in some data and answers a question about the data input. The prompt includes a few exemplars which are adopted from [here](https://github.com/reasoning-machines/pal/blob/main/pal/prompt/penguin_prompt.py).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wH5mVOmfC0n3"
      },
      "outputs": [],
      "source": [
        "# lm instance\n",
        "llm = OpenAI(model_name='text-davinci-003', temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiH294RXC0n3"
      },
      "outputs": [],
      "source": [
        "question = \"Which is the oldest penguin?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHG-XsSpC0n3"
      },
      "outputs": [],
      "source": [
        "PENGUIN_PROMPT = '''\n",
        "\"\"\"\n",
        "Q: Here is a table where the first line is a header and each subsequent line is a penguin:\n",
        "name, age, height (cm), weight (kg)\n",
        "Louis, 7, 50, 11\n",
        "Bernard, 5, 80, 13\n",
        "Vincent, 9, 60, 11\n",
        "Gwen, 8, 70, 15\n",
        "For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.\n",
        "We now add a penguin to the table:\n",
        "James, 12, 90, 12\n",
        "How many penguins are less than 8 years old?\n",
        "\"\"\"\n",
        "# Put the penguins into a list.\n",
        "penguins = []\n",
        "penguins.append(('Louis', 7, 50, 11))\n",
        "penguins.append(('Bernard', 5, 80, 13))\n",
        "penguins.append(('Vincent', 9, 60, 11))\n",
        "penguins.append(('Gwen', 8, 70, 15))\n",
        "# Add penguin James.\n",
        "penguins.append(('James', 12, 90, 12))\n",
        "# Find penguins under 8 years old.\n",
        "penguins_under_8_years_old = [penguin for penguin in penguins if penguin[1] < 8]\n",
        "# Count number of penguins under 8.\n",
        "num_penguin_under_8 = len(penguins_under_8_years_old)\n",
        "answer = num_penguin_under_8\n",
        "\"\"\"\n",
        "Q: Here is a table where the first line is a header and each subsequent line is a penguin:\n",
        "name, age, height (cm), weight (kg)\n",
        "Louis, 7, 50, 11\n",
        "Bernard, 5, 80, 13\n",
        "Vincent, 9, 60, 11\n",
        "Gwen, 8, 70, 15\n",
        "For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.\n",
        "Which is the youngest penguin?\n",
        "\"\"\"\n",
        "# Put the penguins into a list.\n",
        "penguins = []\n",
        "penguins.append(('Louis', 7, 50, 11))\n",
        "penguins.append(('Bernard', 5, 80, 13))\n",
        "penguins.append(('Vincent', 9, 60, 11))\n",
        "penguins.append(('Gwen', 8, 70, 15))\n",
        "# Sort the penguins by age.\n",
        "penguins = sorted(penguins, key=lambda x: x[1])\n",
        "# Get the youngest penguin's name.\n",
        "youngest_penguin_name = penguins[0][0]\n",
        "answer = youngest_penguin_name\n",
        "\"\"\"\n",
        "Q: Here is a table where the first line is a header and each subsequent line is a penguin:\n",
        "name, age, height (cm), weight (kg)\n",
        "Louis, 7, 50, 11\n",
        "Bernard, 5, 80, 13\n",
        "Vincent, 9, 60, 11\n",
        "Gwen, 8, 70, 15\n",
        "For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.\n",
        "What is the name of the second penguin sorted by alphabetic order?\n",
        "\"\"\"\n",
        "# Put the penguins into a list.\n",
        "penguins = []\n",
        "penguins.append(('Louis', 7, 50, 11))\n",
        "penguins.append(('Bernard', 5, 80, 13))\n",
        "penguins.append(('Vincent', 9, 60, 11))\n",
        "penguins.append(('Gwen', 8, 70, 15))\n",
        "# Sort penguins by alphabetic order.\n",
        "penguins_alphabetic = sorted(penguins, key=lambda x: x[0])\n",
        "# Get the second penguin sorted by alphabetic order.\n",
        "second_penguin_name = penguins_alphabetic[1][0]\n",
        "answer = second_penguin_name\n",
        "\"\"\"\n",
        "{question}\n",
        "\"\"\"\n",
        "'''.strip() + '\\n'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr1eK1HxC0n4"
      },
      "source": [
        "Now that we have the prompt and question. We can send it to the model. It should output the steps, in code, needed to get the solution to the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4XyEijZC0n4"
      },
      "outputs": [],
      "source": [
        "llm_out = llm(PENGUIN_PROMPT.format(question=question))\n",
        "print(llm_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53dJUaiGC0n4"
      },
      "outputs": [],
      "source": [
        "exec(llm_out)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VrBfPgUC0n5"
      },
      "source": [
        "That's the correct answer! Vincent is the oldest penguin."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "promptlecture",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f38e0373277d6f71ee44ee8fea5f1d408ad6999fda15d538a69a99a1665a839d"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}