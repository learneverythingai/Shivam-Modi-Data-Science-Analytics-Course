{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/learneverythingai/Shivam-Modi-Data-Science-Analytics-Course/blob/main/Deep%20Learning%20Course/NLP_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Author and Instructor of this Notebook is **Shivam Modi**.\n",
        "\n",
        "## LinkedIn: https://www.linkedin.com/in/shivam-modi-datascientist/"
      ],
      "metadata": {
        "id": "y9URXCQsM1gg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agHY5TarKFNV"
      },
      "source": [
        "<a id=\"6\"></a>\n",
        "<center><h1><u>Developing Simple Chatbot using Python and Deep Learning</h1></u></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS_ErRkzc-zw",
        "outputId": "e19b942e-daff-4685-deb8-91a5ad5a1d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjLOCw7M9NQ-"
      },
      "source": [
        "A Chatbot is an application that is used to manage an online chat conversation through text or text to speech format. Most of the chatbots are accessed online through various websites or assistances with a popup.\n",
        "\n",
        "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTAN0l-JaSeHh7F1fwn1ZEAzG4s2FMWHzyrtA&usqp=CAU)\n",
        "\n",
        "Examples:- E-commerce websites, health, news, etc.\n",
        "\n",
        "\n",
        "\n",
        "Basic workflow for building chatbot:\n",
        "\n",
        "1. Import and load the data file\n",
        "2. Preprocess data\n",
        "3. Create training and testing data\n",
        "4. Build the model\n",
        "5. Predict the response\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZRY_8jtAafY"
      },
      "source": [
        "Note:\n",
        "---\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "I have provided the files in the links given below:<br>\n",
        "static:<br>\n",
        "https://drive.google.com/drive/folders/1o48FdC0MeAQoA_0xANrPpg-pXQ5aCwD6?usp=sharing\n",
        "\n",
        "templates:<br>\n",
        "https://drive.google.com/drive/folders/1bVIVMDEXRSFvOAlCRkzIll_S3cqWJwPZ?usp=sharing\n",
        "\n",
        "intents.json:<br>\n",
        "https://drive.google.com/file/d/1z4L3Oba6biQgl6gnMc2SUVmzcMUkqcjb/view?usp=sharing\n",
        "\n",
        "\n",
        "You need to upload the files in the given format only. Rest other files will get create while executing the code.<br>\n",
        "If you are unable to upload the files these the proper format then the code might give error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoHefELWyL_4"
      },
      "outputs": [],
      "source": [
        "# import the  libraries\n",
        "import random\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "import pickle\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE0f5B0LMi3X",
        "outputId": "4ac87d21-b749-4aa3-a70d-cccbfe572a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#import nltk,WordNetLemmatizer\n",
        "#download punkt and wordnet \n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE6C_OfVYqE0"
      },
      "source": [
        "Now create a folder in drive and add path here to make use of files and intents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_08StUaYOrZ",
        "outputId": "add558a9-818c-4afb-d590-a9278b2e6975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Aiforeverything/Chatbot\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Aiforeverything/Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xTytLjrmgAw",
        "outputId": "bfb0a135-24a9-42db-ab5a-68198a11b28b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chatbot_model.h5  intents.json\t\t\t\tstatic\t  words.pkl\n",
            "classes.pkl\t  learneverythingaiChatbot_final.ipynb\ttemplate\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf4tYD8Oz45c"
      },
      "source": [
        "\n",
        "\n",
        "Now can download the intent file here:\n",
        "https://drive.google.com/file/d/1z4L3Oba6biQgl6gnMc2SUVmzcMUkqcjb/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpfOprIWMnbi"
      },
      "outputs": [],
      "source": [
        "# init file\n",
        "#create a lists of words, classes and documents.\n",
        "#open the intent.json file and read that file\n",
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = [\"?\", \"!\"]\n",
        "data_file = open(\"/content/drive/MyDrive/Aiforeverything/Chatbot/intents.json\").read()\n",
        "intents = json.loads(data_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiSFCRMuMsH3"
      },
      "outputs": [],
      "source": [
        "#iterate over intents\n",
        "#now iterate over the patterns\n",
        "# take each word and tokenize it\n",
        "for intent in intents[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        words.extend(w)\n",
        "        documents.append((w, intent[\"tag\"]))\n",
        "        if intent[\"tag\"] not in classes:\n",
        "            classes.append(intent[\"tag\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zn5R0D2qMwK_"
      },
      "outputs": [],
      "source": [
        "# lemmatizer\n",
        "#first the lower th words and then iterate throught words and check if it is not present in the ignore words\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "classes = sorted(list(set(classes)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FyTs8-wM1q0",
        "outputId": "b4c4cf56-223b-4282-d425-bd4b50f637ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 documents\n",
            "55 classes ['AI', 'abbr', 'artificial', 'bend', 'body', 'bot1', 'breathe', 'business', 'chatbot', 'chatterbox', 'clone', 'comp', 'computer', 'control', 'cramped', 'date', 'death', 'do', 'events', 'fav', 'fight', 'goodbye', 'greetings', 'hardware', 'hobby', 'idea', 'imortal', 'lang', 'laugh', 'lie', 'machine', 'malfunction', 'motormouth', 'move', 'name', 'name1', 'need', 'noanswer', 'os', 'program', 'programming', 'ratchet', 'robotics', 'robots', 'robotss', 'sapient', 'sense', 'sentiment', 'shoe', 'sound', 'stupid', 'thanks', 'usage', 'who', 'wt']\n",
            "126 unique lemmatized words [\"'m\", \"'s\", ',', 'a', 'ai', 'all', 'allowed', 'am', 'an', 'are', 'artificial', 'awesome', 'be', 'being', 'bend', 'body', 'bot', 'breathe', 'business', 'bye', 'can', 'chat', 'chatterbox', 'clone', 'coffee', 'computer', 'control', 'cramped', 'data', 'date', 'die', 'do', 'entity', 'event', 'favorite', 'favour', 'fight', 'for', 'good', 'great', 'hardware', 'haroo', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'hobby', 'holla', 'hope', 'how', 'i', 'idea', 'immortal', 'in', 'is', 'it', 'jaw', 'kind', 'language', 'later', 'laugh', 'lie', 'like', 'linguistic', 'making', 'malfunction', 'mate', 'me', 'motormouth', 'move', 'my', 'name', 'need', 'not', 'of', 'okay', 'on', 'operating', 'out', 'over', 'popping', 'product', 'program', 'programming', 'purpose', 'ratchet', 'robot', 'robotics', 'sapient', 'see', 'sense', 'sentient', 'shoe', 'should', 'size', 'sound', 'stupid', 'system', 'take', 'thank', 'thanks', 'thankyou', 'that', 'the', 'there', 'to', 'true', 'type', 'upcoming', 'use', 'walk', 'want', 'wassup', 'what', 'when', 'who', 'will', 'work', 'wow', 'written', 'wtf', 'yaw', 'you', 'your']\n"
          ]
        }
      ],
      "source": [
        "#print the len of documents\n",
        "print(len(documents), \"documents\")\n",
        "print(len(classes), \"classes\", classes)\n",
        "print(len(words), \"unique lemmatized words\", words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jnGj6u_AupG"
      },
      "source": [
        "\n",
        "\n",
        "For more about pickle refer :<br>\n",
        "https://docs.python.org/3/library/pickle.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6QW1yoSM9gF"
      },
      "outputs": [],
      "source": [
        "#create pickle dump for words and open with words.pkl and write in wb mode\n",
        "pickle.dump(words, open(\"words.pkl\", \"wb\"))\n",
        "#create pickle dump for classes and open with classes.pkl and write in wb mode\n",
        "pickle.dump(classes, open(\"classes.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YyOMiDtNAQ5"
      },
      "outputs": [],
      "source": [
        "# training initializer\n",
        "# initializing training data\n",
        "training = []\n",
        "output_empty = [0] * len(classes)\n",
        "for doc in documents:\n",
        "    bag = []\n",
        "    pattern_words = doc[0]\n",
        "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "    for w in words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "    training.append([bag, output_row])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkSJzdS3NETD",
        "outputId": "40157c06-1534-4d8c-c35f-742a99b37f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "# shuffle our features and turn into np.array\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "# create train and test lists. X - patterns, Y - intents\n",
        "train_x = list(training[:, 0])\n",
        "train_y = list(training[:, 1])\n",
        "print(\"Training data created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaSCjaSmJaTS"
      },
      "source": [
        "Now we train our model by  creating a model that has 3 layers.\n",
        "The first layer is 128 neurons, the second layer is 64 neurons and the third output layer contains number of neurons equal to number of intents to predict output intent with softmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDxtDQt_NIRf"
      },
      "outputs": [],
      "source": [
        "# actual training\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r82ZIAZuKNt6"
      },
      "source": [
        "After adding all the hidden layers, now we check the summary of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUUY2oUkNTM9",
        "outputId": "50c2629e-982c-4d98-a0d2-d1d83fb97377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               16256     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 55)                3575      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,087\n",
            "Trainable params: 28,087\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#check the summary \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMilz3_aKeDH"
      },
      "source": [
        "The model is compiled with a loss function of categorical_crossentropy and an optimizer of SGD.The metrics for this model are accuracy, which is calculated as the percentage of correct predictions in total number of predictions made.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GJDpGnwNQDJ"
      },
      "outputs": [],
      "source": [
        "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
        "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIpv_bXYNXZt",
        "outputId": "c280a6bc-6feb-4b1a-f48f-91c8da660c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "20/20 [==============================] - 1s 2ms/step - loss: 4.0051 - accuracy: 0.0000e+00\n",
            "Epoch 2/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.9277 - accuracy: 0.1500\n",
            "Epoch 3/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.8842 - accuracy: 0.0900\n",
            "Epoch 4/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.8100 - accuracy: 0.1300\n",
            "Epoch 5/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.6929 - accuracy: 0.1800\n",
            "Epoch 6/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.6401 - accuracy: 0.1900\n",
            "Epoch 7/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.5439 - accuracy: 0.1600\n",
            "Epoch 8/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.4328 - accuracy: 0.1800\n",
            "Epoch 9/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.3568 - accuracy: 0.2100\n",
            "Epoch 10/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.2868 - accuracy: 0.2000\n",
            "Epoch 11/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.1920 - accuracy: 0.2000\n",
            "Epoch 12/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.0510 - accuracy: 0.3000\n",
            "Epoch 13/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.9517 - accuracy: 0.2400\n",
            "Epoch 14/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.8362 - accuracy: 0.3000\n",
            "Epoch 15/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.6747 - accuracy: 0.3600\n",
            "Epoch 16/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.6794 - accuracy: 0.3200\n",
            "Epoch 17/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.6036 - accuracy: 0.3800\n",
            "Epoch 18/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.4172 - accuracy: 0.3900\n",
            "Epoch 19/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.3111 - accuracy: 0.4000\n",
            "Epoch 20/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.3431 - accuracy: 0.4000\n",
            "Epoch 21/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.2905 - accuracy: 0.4200\n",
            "Epoch 22/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0401 - accuracy: 0.4200\n",
            "Epoch 23/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.9793 - accuracy: 0.4900\n",
            "Epoch 24/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0058 - accuracy: 0.4700\n",
            "Epoch 25/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.8917 - accuracy: 0.4500\n",
            "Epoch 26/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.9696 - accuracy: 0.5100\n",
            "Epoch 27/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.9474 - accuracy: 0.4900\n",
            "Epoch 28/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.8201 - accuracy: 0.4900\n",
            "Epoch 29/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.6377 - accuracy: 0.5600\n",
            "Epoch 30/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.5176 - accuracy: 0.5900\n",
            "Epoch 31/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.6624 - accuracy: 0.4800\n",
            "Epoch 32/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.4870 - accuracy: 0.5900\n",
            "Epoch 33/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.4806 - accuracy: 0.5900\n",
            "Epoch 34/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.4590 - accuracy: 0.5700\n",
            "Epoch 35/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.4641 - accuracy: 0.5400\n",
            "Epoch 36/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.3130 - accuracy: 0.6200\n",
            "Epoch 37/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.1834 - accuracy: 0.7000\n",
            "Epoch 38/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.2436 - accuracy: 0.7000\n",
            "Epoch 39/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.2485 - accuracy: 0.6000\n",
            "Epoch 40/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.0835 - accuracy: 0.6500\n",
            "Epoch 41/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.3568 - accuracy: 0.5900\n",
            "Epoch 42/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.2257 - accuracy: 0.5900\n",
            "Epoch 43/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.1359 - accuracy: 0.7200\n",
            "Epoch 44/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.9841 - accuracy: 0.7500\n",
            "Epoch 45/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.0716 - accuracy: 0.7400\n",
            "Epoch 46/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.0819 - accuracy: 0.6200\n",
            "Epoch 47/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.0871 - accuracy: 0.6800\n",
            "Epoch 48/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.9932 - accuracy: 0.6900\n",
            "Epoch 49/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.9510 - accuracy: 0.7200\n",
            "Epoch 50/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.0060 - accuracy: 0.6800\n",
            "Epoch 51/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.9544 - accuracy: 0.7000\n",
            "Epoch 52/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.8536 - accuracy: 0.7600\n",
            "Epoch 53/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.8757 - accuracy: 0.7600\n",
            "Epoch 54/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.9331 - accuracy: 0.7400\n",
            "Epoch 55/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.9640 - accuracy: 0.7100\n",
            "Epoch 56/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.8242 - accuracy: 0.7800\n",
            "Epoch 57/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.8803 - accuracy: 0.7500\n",
            "Epoch 58/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.9541 - accuracy: 0.7100\n",
            "Epoch 59/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.8372 - accuracy: 0.7500\n",
            "Epoch 60/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7995 - accuracy: 0.7700\n",
            "Epoch 61/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7792 - accuracy: 0.7300\n",
            "Epoch 62/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7861 - accuracy: 0.7600\n",
            "Epoch 63/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.8143 - accuracy: 0.7300\n",
            "Epoch 64/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7510 - accuracy: 0.7600\n",
            "Epoch 65/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7483 - accuracy: 0.7300\n",
            "Epoch 66/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.8964 - accuracy: 0.6900\n",
            "Epoch 67/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7620 - accuracy: 0.7500\n",
            "Epoch 68/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7617 - accuracy: 0.7600\n",
            "Epoch 69/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7310 - accuracy: 0.7900\n",
            "Epoch 70/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.8700\n",
            "Epoch 71/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.8277 - accuracy: 0.7600\n",
            "Epoch 72/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.7800\n",
            "Epoch 73/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.8300\n",
            "Epoch 74/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.7600\n",
            "Epoch 75/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7900\n",
            "Epoch 76/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.7600\n",
            "Epoch 77/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.7600\n",
            "Epoch 78/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7106 - accuracy: 0.7900\n",
            "Epoch 79/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.8600\n",
            "Epoch 80/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.7900\n",
            "Epoch 81/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.8200\n",
            "Epoch 82/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.8100\n",
            "Epoch 83/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.8000\n",
            "Epoch 84/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.8500\n",
            "Epoch 85/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.8600\n",
            "Epoch 86/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.8500\n",
            "Epoch 87/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.7500\n",
            "Epoch 88/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.9100\n",
            "Epoch 89/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8600\n",
            "Epoch 90/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8700\n",
            "Epoch 91/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.7800\n",
            "Epoch 92/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8700\n",
            "Epoch 93/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.8500\n",
            "Epoch 94/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.8400\n",
            "Epoch 95/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.9000\n",
            "Epoch 96/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8700\n",
            "Epoch 97/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8900\n",
            "Epoch 98/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8900\n",
            "Epoch 99/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.7900\n",
            "Epoch 100/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.8400\n",
            "Epoch 101/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.9000\n",
            "Epoch 102/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8600\n",
            "Epoch 103/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8600\n",
            "Epoch 104/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.9000\n",
            "Epoch 105/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8200\n",
            "Epoch 106/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.8300\n",
            "Epoch 107/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8600\n",
            "Epoch 108/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.9100\n",
            "Epoch 109/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8700\n",
            "Epoch 110/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8300\n",
            "Epoch 111/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8800\n",
            "Epoch 112/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8700\n",
            "Epoch 113/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.8100\n",
            "Epoch 114/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8800\n",
            "Epoch 115/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8900\n",
            "Epoch 116/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.9300\n",
            "Epoch 117/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8900\n",
            "Epoch 118/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8700\n",
            "Epoch 119/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.9100\n",
            "Epoch 120/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.9100\n",
            "Epoch 121/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.8000\n",
            "Epoch 122/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8400\n",
            "Epoch 123/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.9000\n",
            "Epoch 124/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8900\n",
            "Epoch 125/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8700\n",
            "Epoch 126/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.9200\n",
            "Epoch 127/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8800\n",
            "Epoch 128/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.9400\n",
            "Epoch 129/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.8000\n",
            "Epoch 130/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8800\n",
            "Epoch 131/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8100\n",
            "Epoch 132/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8500\n",
            "Epoch 133/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8600\n",
            "Epoch 134/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8700\n",
            "Epoch 135/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8800\n",
            "Epoch 136/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8700\n",
            "Epoch 137/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8900\n",
            "Epoch 138/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.9200\n",
            "Epoch 139/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8900\n",
            "Epoch 140/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.9100\n",
            "Epoch 141/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8500\n",
            "Epoch 142/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.9200\n",
            "Epoch 143/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8700\n",
            "Epoch 144/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.9300\n",
            "Epoch 145/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8600\n",
            "Epoch 146/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8500\n",
            "Epoch 147/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8900\n",
            "Epoch 148/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.9000\n",
            "Epoch 149/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8300\n",
            "Epoch 150/150\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8700\n",
            "model created\n"
          ]
        }
      ],
      "source": [
        "# fitting our model \n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=150, batch_size=5, verbose=1)\n",
        "#save our model in .h5 extension \n",
        "model.save(\"chatbot_model.h5\", hist)\n",
        "print(\"model created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbhUTkqMU7DI"
      },
      "source": [
        "Now our model is trained, So we have to deploy our model with an interface.\n",
        "So for flask implementation we need IDLEs for implementation. But in this project we are going to implement flask with the help of Google Colab Notebook.\n",
        "\n",
        "So lets start with Deployment\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAyym0wVWTbo"
      },
      "source": [
        "First we will install flask_ngrok for flask implementation in google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzPGJp2kz1fe",
        "outputId": "41f55ab8-49af-4a27-dcf6-825f6177385b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "#installing flask_ngrok with pip \n",
        "!pip install flask_ngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XDE4-g2bQTn"
      },
      "source": [
        "Now we will install and download the ngrok with these commands for installing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov7u0CJb84Cl",
        "outputId": "130eb6fc-1348-4ad8-ea8a-30231b21fe90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb https://ngrok-agent.s3.amazonaws.com buster main\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [90.7 kB]\n",
            "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,533 kB]\n",
            "Get:12 https://ngrok-agent.s3.amazonaws.com buster InRelease [20.3 kB]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,100 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,937 kB]\n",
            "Get:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,369 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,141 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,310 kB]\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [903 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,089 kB]\n",
            "Get:24 https://ngrok-agent.s3.amazonaws.com buster/main amd64 Packages [1,262 B]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,070 kB]\n",
            "Get:26 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:27 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [47.7 kB]\n",
            "Fetched 17.0 MB in 4s (4,837 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "38 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  ngrok\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 5,464 kB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 https://ngrok-agent.s3.amazonaws.com buster/main amd64 ngrok amd64 3.0.6 [5,464 kB]\n",
            "Fetched 5,464 kB in 1s (5,105 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package ngrok.\n",
            "(Reading database ... 155680 files and directories currently installed.)\n",
            "Preparing to unpack .../archives/ngrok_3.0.6_amd64.deb ...\n",
            "Unpacking ngrok (3.0.6) ...\n",
            "Setting up ngrok (3.0.6) ...\n"
          ]
        }
      ],
      "source": [
        "!curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list && sudo apt update && sudo apt install ngrok   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meLhRXLhcflg"
      },
      "source": [
        "After importing the libraries, We need to add ngrok token here.\n",
        "\n",
        "![](https://help.polymer3d.app/assets/ngrok-token.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36IFSZNA8o_W",
        "outputId": "8552b045-ed92-4074-dec8-b084a5bc4705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "#!ngrok add token here\n",
        "#!ngrok authtoken 23mMEZeu7mTNdBDg1w3DctEhXpl_5MeopxnhcRvxuaxJGLEk2\n",
        "!ngrok authtoken 2DLhfpaJspqieAYJCdEEIJIKSft_4PuqHs532NU9A323LHzWD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv8DWJbL7POS"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "#import flask \n",
        "from flask import *\n",
        "#import run_with_ngrok from flask_ngrok \n",
        "from flask_ngrok import run_with_ngrok\n",
        "#import radom\n",
        "import random\n",
        "#import numpy\n",
        "import numpy as np\n",
        "#import pickle\n",
        "import pickle\n",
        "#import json\n",
        "import json\n",
        "#import load_model from tensorflow\n",
        "from tensorflow.keras.models import load_model\n",
        "#import nltk\n",
        "import nltk\n",
        "#import WordNetLemmatizer from nltk.stem\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "#create a object of WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJxwSXwYfbSZ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rfvAi3rn2th",
        "outputId": "6981888f-2dcf-45fc-8d51-cc998f9d21f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread _colab_inspector_thread:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/google/colab/_debugpy.py\", line 64, in inspector_thread\n",
            "    _variable_inspector.run(shell, time)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/google/colab/_variable_inspector.py\", line 27, in run\n",
            "    globals().clear()\n",
            "TypeError: 'module' object is not callable\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyopenssl\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     || 55 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting cryptography>=35.0\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     || 4.1 MB 18.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=35.0->pyopenssl) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=35.0->pyopenssl) (2.21)\n",
            "Installing collected packages: cryptography, pyopenssl\n",
            "Successfully installed cryptography-37.0.4 pyopenssl-22.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyopenssl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-CtB3zq0Hdc",
        "outputId": "1d74d049-1bbf-41dd-d51e-3eb7985aec80"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://81be-35-199-55-191.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        }
      ],
      "source": [
        "#create a flask app\n",
        "app = Flask(__name__)\n",
        "#run_with_ngrok(app)\n",
        "run_with_ngrok(app) \n",
        "\n",
        "# chat initialization\n",
        "#load model chatbot_model.h5\n",
        "model = load_model(\"chatbot_model.h5\")\n",
        "#open and reading the intents.json\n",
        "intents = json.loads(open(\"/content/drive/MyDrive/Aiforeverything/Chatbot/intents.json\").read())\n",
        "#pickle load for words and open with words.pkl and rb mode\n",
        "words = pickle.load(open(\"words.pkl\", \"rb\"))\n",
        "#pickle load for classes and open with classes.pkl and rb mode\n",
        "classes = pickle.load(open(\"classes.pkl\", \"rb\"))\n",
        "\n",
        "#app.route(\"/\")\n",
        "@app.route(\"/\")\n",
        "#def a home function to render index page\n",
        "def home():\n",
        "    #return render template index.html\n",
        "    return render_template(\"/content/drive/MyDrive/Aiforeverything/Chatbot/template/index.html\")\n",
        "\n",
        "#@app.route(\"/get\",methods=[\"POST\"])\n",
        "@app.route(\"/get\", methods=[\"POST\"])\n",
        "#define a chatbot response\n",
        "def chatbot_response():\n",
        "    #requesting a msg \n",
        "    #msg = request.form[\"msg\"]\n",
        "    msg = request.form[\"msg\"]\n",
        "    #if user give his/her name so to store that name in a variable\n",
        "    #if msg.startswith('my name is'):\n",
        "    if msg.startswith('my name is'):\n",
        "        #now name =msg[11:]\n",
        "        name = msg[11:]\n",
        "        #use predict class and pass the msg and model parameter[#ints = predict_class(msg, model)]\n",
        "        ints = predict_class(msg, model)\n",
        "        #use getResponse and pass the ints and intents parameters[res1 = getResponse(ints, intents)]\n",
        "        res1 = getResponse(ints, intents)\n",
        "        #replace with name[res =res1.replace(\"{n}\",name)]\n",
        "        res =res1.replace(\"{n}\",name)\n",
        "    #if user type hi my name is so length will be increased so +3\n",
        "    elif msg.startswith('hi my name is'):\n",
        "        #now name =msg[14:]\n",
        "        name = msg[14:]\n",
        "        #use predict class and pass the msg and model parameter[#ints = predict_class(msg, model)]\n",
        "        ints = predict_class(msg, model)\n",
        "        #use getResponse and pass the ints and intents parameters[res1 = getResponse(ints, intents)]\n",
        "        res1 = getResponse(ints, intents)\n",
        "        #replace with name[res =res1.replace(\"{n}\",name)]\n",
        "        res =res1.replace(\"{n}\",name)\n",
        "    #if user does not type his/her name \n",
        "    #esle\n",
        "    else:\n",
        "        #use predict class and pass the msg and model parameter[#ints = predict_class(msg, model)] \n",
        "        ints = predict_class(msg, model)\n",
        "        #use getResponse and pass the ints and intents parameters[res1 = getResponse(ints, intents)]\n",
        "        res = getResponse(ints, intents)\n",
        "    #return the res\n",
        "    return res\n",
        "\n",
        "\n",
        "# chat functionalities\n",
        "#define a function to clean or preprocess the sentences\n",
        "def clean_up_sentence(sentence):\n",
        "    #tokenizing the sentences\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    #lemmatizing the sentences\n",
        "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
        "    #return preprocessed words or sentences\n",
        "    return sentence_words\n",
        "\n",
        "\n",
        "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
        "#defining a function with sentences and words as parameter\n",
        "def bow(sentence, words, show_details=True):\n",
        "    # tokenize the pattern\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    # bag of words - matrix of N words, vocabulary matrix[bag = [0] * len(words)]\n",
        "    bag = [0] * len(words)\n",
        "    #iterate for sentences[for s in sentence_words:]\n",
        "    for s in sentence_words:\n",
        "        #now enumerate over words\n",
        "        for i, w in enumerate(words):\n",
        "          #if w=s assign 1 if current word is in the vocabulary position\n",
        "            if w == s:\n",
        "                # assign 1 if current word is in the vocabulary position\n",
        "                bag[i] = 1\n",
        "                #if show_details\n",
        "                if show_details:\n",
        "                    #print found baf i w\n",
        "                    print(\"found in bag: %s\" % w)\n",
        "    #return numpy array with bag\n",
        "    return np.array(bag)\n",
        "\n",
        "#define function of predict class with sentence and model as parameter\n",
        "def predict_class(sentence, model):\n",
        "    # filter out predictions below a threshold\n",
        "    #creating bow of sentence, words [p = bow(sentence, words, show_details=False)]\n",
        "    p = bow(sentence, words, show_details=False)\n",
        "    #we will predict with numpy array taking 0th postion[res = model.predict(np.array([p]))[0]] \n",
        "    res = model.predict(np.array([p]))[0]\n",
        "    #intiailize the threshold value=0.25\n",
        "    ERROR_THRESHOLD = 0.25\n",
        "    #results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "    # sort by strength of probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    #creating a list\n",
        "    return_list = []\n",
        "    #iterating in results\n",
        "    for r in results:\n",
        "        #appending intent and probabiltiy[ return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})]\n",
        "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
        "    #return list\n",
        "    return return_list\n",
        "\n",
        "\n",
        "#defing a getResponse with ints and intent_json as parameter\n",
        "def getResponse(ints, intents_json):\n",
        "    #tag=ints[0][intent]\n",
        "    tag = ints[0][\"intent\"]\n",
        "    #storing all intents in list of intents[list_of_intents = intents_json[\"intents\"]]\n",
        "    list_of_intents = intents_json[\"intents\"]\n",
        "    #iterate over lists of intents\n",
        "    for i in list_of_intents:\n",
        "        # if tag == tag then print respones\n",
        "        if i[\"tag\"] == tag:\n",
        "            result = random.choice(i[\"responses\"])\n",
        "            break\n",
        "    #return result\n",
        "    return result\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        "if __name__ == \"__main__\":\n",
        "    #run the app \n",
        "    app.run()\n",
        "    app.debug = True\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}