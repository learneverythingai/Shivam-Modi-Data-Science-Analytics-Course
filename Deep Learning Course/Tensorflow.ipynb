{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/learneverythingai/Shivam-Modi-Data-Science-Analytics-Course/blob/main/Deep%20Learning%20Course/Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Author and Instructor of this Notebook is **Shivam Modi**.\n",
        "\n",
        "## LinkedIn: https://www.linkedin.com/in/shivam-modi-datascientist/"
      ],
      "metadata": {
        "id": "y9URXCQsM1gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow\n",
        "Tensorlow is a deep learning library created by Google and is used to build, design and train deep learning models. The tensorflow operations in neural networks performed on multidimensional data arrays or tensors.\n",
        "\n",
        "(reference: https://youtu.be/yjprpOoH5c8), use captions for better experience\n",
        "\n",
        "## Installing tensorflow\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "xGmkKitY-89Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import `tensorflow`\n",
        "import tensorflow as tf\n",
        "\n",
        "# Initialize two constants\n",
        "x1 = tf.constant([7,4,9,3])\n",
        "x2 = tf.constant([1,8,2,4])\n",
        "\n",
        "# Multiply\n",
        "result = tf.multiply(x1, x2)\n",
        "\n",
        "# Print the result\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3NpQYmvC1gL",
        "outputId": "6602ba13-a689-4703-d247-6df6fa0e13a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 7 32 18 12], shape=(4,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensorflow is used for:\n",
        "\n",
        "\n",
        "1.   Loading and exploring the data\n",
        "2.   Feature extraction\n",
        "3.   Modeling Neural Network\n",
        "4.   Evaluating the Neural Network\n",
        "\n"
      ],
      "metadata": {
        "id": "SqJRwFLU-85x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Operations using Tensorflow\n",
        "$Eager-execution$ is a powerful execution environment that evaluates operations immediately. It does not build graphs, and the operations return actual values instead of computational graphs to run later."
      ],
      "metadata": {
        "id": "Fg8C3_kKTaGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "_NXH9GTiTr8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.executing_eagerly()) #checking weather eager mode is enabled or not\n",
        "print(\"Enabling eager mode!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_sJMiTdUI4B",
        "outputId": "3fd4ed5b-8eb9-4724-8d1a-a0730054a394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Enabling eager mode!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**if using tf version less than 2.0 then can be enabled using below comand line**\n",
        "<p> tf.enable_eager_execution()"
      ],
      "metadata": {
        "id": "i47L2X88U8AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define constant tensors\n",
        "a = tf.constant(17)\n",
        "print(\"a = %i\" % a)\n",
        "b = tf.constant(18)\n",
        "print(\"b = %i\" % b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOxme2yyU7R8",
        "outputId": "a8c7a626-ac6a-481c-cef7-8f7dbbdbb630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Define constant tensors\n",
            "a = 17\n",
            "b = 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the operation without the need for tf.Session\n",
        "c = a + b\n",
        "print(\"a + b = %i\" % c)\n",
        "d = a * b\n",
        "print(\"a * b = %i\" % d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEen-DrOUI0g",
        "outputId": "0e714185-aad2-4d46-957f-217f6d49691f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running operations, without tf.Session\n",
            "a + b = 35\n",
            "a * b = 306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mixing operations with Tensors and Numpy Arrays\n",
        "# Define constant tensors\n",
        "a = tf.constant([[7., 4.],[0., 9.]], dtype=tf.float32)\n",
        "print(\"Tensor:\\n a = %s\" % a)\n",
        "b = np.array([[0., 6.],[4., 8.]], dtype=np.float32)\n",
        "print(\"NumpyArray:\\n b = %s\" % b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwbYj64dUIx-",
        "outputId": "bbd6f398-2fd2-449f-bd87-5dfbda0dd4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor:\n",
            " a = tf.Tensor(\n",
            "[[7. 4.]\n",
            " [0. 9.]], shape=(2, 2), dtype=float32)\n",
            "NumpyArray:\n",
            " b = [[0. 6.]\n",
            " [4. 8.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the operation without the need for tf.Session\n",
        "c = a + b\n",
        "print(\"a + b = %s\" % c)\n",
        "\n",
        "d = tf.matmul(a, b)\n",
        "print(\"a * b = %s\" % d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-CPGCROUIvE",
        "outputId": "0fa79149-08c8-4c97-dded-10c1024f461f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a + b = tf.Tensor(\n",
            "[[ 7. 10.]\n",
            " [ 4. 17.]], shape=(2, 2), dtype=float32)\n",
            "a * b = tf.Tensor(\n",
            "[[16. 74.]\n",
            " [36. 72.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto encoder with Tensorflow, keras\n",
        "$Autoencoders$ are a type of unsupervised neural network helps to:\n",
        "* Accept an input set of data (i.e., the input)\n",
        "* Internally compress the input data and quantifies the input)\n",
        "* Reconstruct the input data i.e., the output\n",
        "<p> In general autoencoder have two components:\n",
        "1. $Encoder$ : Accepts the input data and compresses it into the latent-space\n",
        "2. $Decoder$ : The decoder is responsible for accepting the latent-space and then reconstructing the original input."
      ],
      "metadata": {
        "id": "CFxwMf3aZbm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import time"
      ],
      "metadata": {
        "id": "I_56LA7FUIsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the MNIST dataset\n",
        "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvR-JZzRUIpz",
        "outputId": "5b8b7097-ea67-4391-890e-0b49664486fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reshaping the images\n",
        "def preprocess_images(images):\n",
        "  images = images.reshape((images.shape[0], 28, 28, 1)) / 255.\n",
        "  return np.where(images > .5, 1.0, 0.0).astype('float32')\n",
        "\n",
        "train_images = preprocess_images(train_images)\n",
        "test_images = preprocess_images(test_images)"
      ],
      "metadata": {
        "id": "2D8DwxR1UIm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = print(train_images.shape)\n",
        "test_size = print(test_images.shape)\n",
        "batch_size = 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-WTTpP5UIkG",
        "outputId": "9392c8f2-6d87-470a-e3c8-64677b239b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 60000\n",
        "test_size = 10000\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "1o0ssRRpb2dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using tf.data to batch and shuffling the data\n",
        "train_dataset = (tf.data.Dataset.from_tensor_slices(train_images).shuffle(train_size).batch(batch_size))\n",
        "test_dataset = (tf.data.Dataset.from_tensor_slices(test_images).shuffle(test_size).batch(batch_size))"
      ],
      "metadata": {
        "id": "bwMaYHL2UIhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AE(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, latent_dim):\n",
        "    super(AE, self).__init__()\n",
        "    self.latent_dim = latent_dim # Decoder input is usually called latent embedding, and its dimension is latent_dim\n",
        "    self.encoder = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            # No activation\n",
        "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    self.decoder = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
        "            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=64, kernel_size=3, strides=2, padding='same',\n",
        "                activation='relu'),\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=32, kernel_size=3, strides=2, padding='same',\n",
        "                activation='relu'),\n",
        "            # No activation\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "  \n",
        "  def sample(self, eps=None):\n",
        "    if eps is None:\n",
        "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
        "    return self.decode(eps, apply_sigmoid=True)\n",
        "\n",
        "  def encode(self, x):\n",
        "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "    return mean, logvar\n",
        "\n",
        "  def reparameterize(self, mean, logvar):\n",
        "    eps = tf.random.normal(shape=mean.shape)\n",
        "    return eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "  def decode(self, z, apply_sigmoid=False):\n",
        "    logits = self.decoder(z)\n",
        "    if apply_sigmoid:\n",
        "      probs = tf.sigmoid(logits)\n",
        "      return probs\n",
        "    return logits"
      ],
      "metadata": {
        "id": "rsy6EimibdbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining loss function and optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "  log2pi = tf.math.log(2. * np.pi)\n",
        "  return tf.reduce_sum(-.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi), axis=raxis)\n",
        "\n",
        "\n",
        "def compute_loss(model, x):\n",
        "  mean, logvar = model.encode(x)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  x_logit = model.decode(z)\n",
        "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "  logpz = log_normal_pdf(z, 0., 0.)\n",
        "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "\n",
        "\n",
        "def train_step(model, x, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = compute_loss(model, x)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "metadata": {
        "id": "yDnYFyb2c4r2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}